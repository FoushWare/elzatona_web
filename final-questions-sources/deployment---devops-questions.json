{
  "category": "Deployment & DevOps",
  "totalQuestions": 9,
  "exportedAt": "2025-09-30T00:28:57.754Z",
  "questions": [
    {
      "id": "imported-deployment-devops-1759191594554-2",
      "difficulty": "intermediate",
      "title": "CI/CD Pipelines",
      "importedAt": "2025-09-30T00:19:54.554Z",
      "options": [],
      "codeBlock": "# .github/workflows/deploy.yml\nname: Deploy to Production\n\non:\n  push:\n    branches: [main]\n  workflow_dispatch:\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm run test:ci\n\n      - name: Run linting\n        run: npm run lint\n\n      - name: Build application\n        run: npm run build\n\n      - name: Upload coverage\n        uses: codecov/codecov-action@v3\n\n  security:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Run security audit\n        run: npm audit --audit-level high\n\n      - name: Run Snyk security scan\n        uses: snyk/actions/node@master\n        env:\n          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n\n  build:\n    needs: [test, security]\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Log in to Container Registry\n        uses: docker/login-action@v2\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v4\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=ref,event=pr\n            type=sha,prefix={{branch}}-\n            type=raw,value=latest,enable={{is_default_branch}}\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v4\n        with:\n          context: .\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    environment: production\n    steps:\n      - name: Deploy to Kubernetes\n        uses: azure/k8s-deploy@v1\n        with:\n          manifests: |\n            k8s/deployment.yaml\n            k8s/service.yaml\n            k8s/ingress.yaml\n          images: |\n            ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n          namespace: production\n          kubeconfig: ${{ secrets.KUBE_CONFIG }}\n\n      - name: Verify deployment\n        run: |\n          kubectl rollout status deployment/web-app -n production\n          kubectl get pods -n production",
      "learningPaths": [
        "deployment-devops"
      ],
      "correctAnswer": null,
      "isActive": true,
      "content": "Explain CI/CD pipeline design and implementation.",
      "isComplete": false,
      "updatedAt": "2025-09-30T00:19:54.627Z",
      "createdAt": "2025-09-30T00:19:54.627Z",
      "topics": [
        "Docker",
        "CI/CD",
        "AWS",
        "Build Tools"
      ],
      "type": "code",
      "explanation": "**1. GitHub Actions Pipeline:**\n\n# .github/workflows/deploy.yml\nname: Deploy to Production\n\non:\npush:\nbranches: [main]\nworkflow_dispatch:\n\nenv:\nREGISTRY: ghcr.io\nIMAGE_NAME: ${{ github.repository }}\n\njobs:\ntest:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n\n- name: Setup Node.js\nuses: actions/setup-node@v3\nwith:\nnode-version: '18'\ncache: 'npm'\n\n- name: Install dependencies\nrun: npm ci\n\n- name: Run tests\nrun: npm run test:ci\n\n- name: Run linting\nrun: npm run lint\n\n- name: Build application\nrun: npm run build\n\n- name: Upload coverage\nuses: codecov/codecov-action@v3\n\nsecurity:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n\n- name: Run security audit\nrun: npm audit --audit-level high\n\n- name: Run Snyk security scan\nuses: snyk/actions/node@master\nenv:\nSNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n\nbuild:\nneeds: [test, security]\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n\n- name: Set up Docker Buildx\nuses: docker/setup-buildx-action@v2\n\n- name: Log in to Container Registry\nuses: docker/login-action@v2\nwith:\nregistry: ${{ env.REGISTRY }}\nusername: ${{ github.actor }}\npassword: ${{ secrets.GITHUB_TOKEN }}\n\n- name: Extract metadata\nid: meta\nuses: docker/metadata-action@v4\nwith:\nimages: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\ntags: |\ntype=ref,event=branch\ntype=ref,event=pr\ntype=sha,prefix={{branch}}-\ntype=raw,value=latest,enable={{is_default_branch}}\n\n- name: Build and push Docker image\nuses: docker/build-push-action@v4\nwith:\ncontext: .\npush: true\ntags: ${{ steps.meta.outputs.tags }}\nlabels: ${{ steps.meta.outputs.labels }}\ncache-from: type=gha\ncache-to: type=gha,mode=max\n\ndeploy:\nneeds: build\nruns-on: ubuntu-latest\nenvironment: production\nsteps:\n- name: Deploy to Kubernetes\nuses: azure/k8s-deploy@v1\nwith:\nmanifests: |\nk8s/deployment.yaml\nk8s/service.yaml\nk8s/ingress.yaml\nimages: |\n${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\nnamespace: production\nkubeconfig: ${{ secrets.KUBE_CONFIG }}\n\n- name: Verify deployment\nrun: |\nkubectl rollout status deployment/web-app -n production\nkubectl get pods -n production\n\n**2. GitLab CI/CD Pipeline:**\n\n# .gitlab-ci.yml\nstages:\n- test\n- build\n- deploy\n\nvariables:\nDOCKER_DRIVER: overlay2\nDOCKER_TLS_CERTDIR: '/certs'\n\nservices:\n- docker:dind\n\ntest:\nstage: test\nimage: node:18-alpine\nscript:\n- npm ci\n- npm run test:ci\n- npm run lint\n- npm run build\ncoverage: '/Lines\\s*:\\s*(\\d+\\.\\d+)%/'\nartifacts:\nreports:\ncoverage_report:\ncoverage_format: cobertura\npath: coverage/cobertura-coverage.xml\npaths:\n- coverage/\nexpire_in: 1 week\n\nbuild:\nstage: build\nimage: docker:latest\nscript:\n- docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .\n- docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n- docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA $CI_REGISTRY_IMAGE:latest\n- docker push $CI_REGISTRY_IMAGE:latest\nonly:\n- main\n- develop\n\ndeploy_staging:\nstage: deploy\nimage: bitnami/kubectl:latest\nscript:\n- kubectl config use-context staging\n- kubectl set image deployment/web-app web-app=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA -n staging\n- kubectl rollout status deployment/web-app -n staging\nenvironment:\nname: staging\nurl: https://staging.myapp.com\nonly:\n- develop\n\ndeploy_production:\nstage: deploy\nimage: bitnami/kubectl:latest\nscript:\n- kubectl config use-context production\n- kubectl set image deployment/web-app web-app=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA -n production\n- kubectl rollout status deployment/web-app -n production\nenvironment:\nname: production\nurl: https://myapp.com\nwhen: manual\nonly:\n- main",
      "category": "Deployment & DevOps",
      "source": "QuestionsBank"
    },
    {
      "id": "imported-deployment-devops-1759191594555-5",
      "topics": [
        "Docker",
        "CI/CD",
        "AWS",
        "Build Tools"
      ],
      "category": "Deployment & DevOps",
      "updatedAt": "2025-09-30T00:19:54.627Z",
      "learningPaths": [
        "deployment-devops"
      ],
      "options": [],
      "content": "Explain security best practices for deployment and infrastructure.",
      "type": "code",
      "isComplete": false,
      "importedAt": "2025-09-30T00:19:54.555Z",
      "difficulty": "intermediate",
      "isActive": true,
      "codeBlock": "# security-scan.yml\nname: Security Scan\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\njobs:\n  dependency-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Run npm audit\n        run: npm audit --audit-level high\n\n      - name: Run Snyk security scan\n        uses: snyk/actions/node@master\n        env:\n          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n\n  container-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Build Docker image\n        run: docker build -t myapp:latest .\n\n      - name: Run Trivy vulnerability scanner\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: 'myapp:latest'\n          format: 'sarif'\n          output: 'trivy-results.sarif'\n\n      - name: Upload Trivy scan results\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          sarif_file: 'trivy-results.sarif'\n\n  infrastructure-scan:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Run Checkov\n        uses: bridgecrewio/checkov-action@master\n        with:\n          directory: terraform/\n          framework: terraform\n          output_format: sarif\n          output_file_path: checkov-results.sarif\n\n      - name: Upload Checkov results\n        uses: github/codeql-action/upload-sarif@v2\n        with:\n          sarif_file: checkov-results.sarif",
      "correctAnswer": null,
      "explanation": "**1. Security Scanning:**\n\n# security-scan.yml\nname: Security Scan\n\non:\npush:\nbranches: [main, develop]\npull_request:\nbranches: [main]\n\njobs:\ndependency-scan:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n\n- name: Run npm audit\nrun: npm audit --audit-level high\n\n- name: Run Snyk security scan\nuses: snyk/actions/node@master\nenv:\nSNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}\n\ncontainer-scan:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n\n- name: Build Docker image\nrun: docker build -t myapp:latest .\n\n- name: Run Trivy vulnerability scanner\nuses: aquasecurity/trivy-action@master\nwith:\nimage-ref: 'myapp:latest'\nformat: 'sarif'\noutput: 'trivy-results.sarif'\n\n- name: Upload Trivy scan results\nuses: github/codeql-action/upload-sarif@v2\nwith:\nsarif_file: 'trivy-results.sarif'\n\ninfrastructure-scan:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n\n- name: Run Checkov\nuses: bridgecrewio/checkov-action@master\nwith:\ndirectory: terraform/\nframework: terraform\noutput_format: sarif\noutput_file_path: checkov-results.sarif\n\n- name: Upload Checkov results\nuses: github/codeql-action/upload-sarif@v2\nwith:\nsarif_file: checkov-results.sarif\n\n**2. Secrets Management:**\n\n# Kubernetes secrets\napiVersion: v1\nkind: Secret\nmetadata:\nname: app-secrets\ntype: Opaque\ndata:\ndatabase-url: <base64-encoded-database-url>\njwt-secret: <base64-encoded-jwt-secret>\napi-key: <base64-encoded-api-key>",
      "source": "QuestionsBank",
      "createdAt": "2025-09-30T00:19:54.627Z",
      "title": "Security and Compliance"
    },
    {
      "id": "imported-deployment-devops-1759191594556-8",
      "updatedAt": "2025-09-30T00:19:54.627Z",
      "importedAt": "2025-09-30T00:19:54.556Z",
      "category": "Deployment & DevOps",
      "options": [],
      "type": "code",
      "difficulty": "intermediate",
      "source": "QuestionsBank",
      "isActive": true,
      "createdAt": "2025-09-30T00:19:54.627Z",
      "correctAnswer": null,
      "isComplete": false,
      "explanation": "A dependency graph is an internal representation Webpack builds starting from your application's entry point (e.g., index.js). It maps out every import and require statement, creating a graph of how all modules depend on each other. This graph is then used to generate the optimized bundles.\n\n**How Dependency Graph Works:**\n\n// Entry point: src/index.js\nimport React from 'react';\nimport ReactDOM from 'react-dom';\nimport App from './App';\nimport './styles.css';\n\nReactDOM.render(<App />, document.getElementById('root'));\n\n// App.js\nimport Header from './components/Header';\nimport Main from './components/Main';\nimport Footer from './components/Footer';\n\nexport default function App() {\nreturn (\n<div>\n<Header />\n<Main />\n<Footer />\n</div>\n);\n}\n\n// Header.js\nimport Logo from './Logo';\nimport Navigation from './Navigation';\n\nexport default function Header() {\nreturn (\n<header>\n<Logo />\n<Navigation />\n</header>\n);\n}\n\n**Dependency Graph Visualization:**\n\nindex.js\n├── react (node_modules)\n├── react-dom (node_modules)\n├── App.js\n│   ├── Header.js\n│   │   ├── Logo.js\n│   │   └── Navigation.js\n│   ├── Main.js\n│   └── Footer.js\n└── styles.css\n\n**Webpack Bundle Analysis:**\n\n// webpack.config.js\nconst BundleAnalyzerPlugin =\nrequire('webpack-bundle-analyzer').BundleAnalyzerPlugin;\n\nmodule.exports = {\nplugins: [\nnew BundleAnalyzerPlugin({\nanalyzerMode: 'static',\nopenAnalyzer: false,\nreportFilename: 'bundle-report.html',\n}),\n],\n};\n\n// Or use webpack-bundle-analyzer CLI\n// npx webpack-bundle-analyzer dist/bundle.js\n\n**Circular Dependencies:**\n\n// ❌ Bad - Circular dependency\n// user.js\nimport { getPost } from './post.js';\nexport const getUser = id => {\n/* ... */\n};\n\n// post.js\nimport { getUser } from './user.js';\nexport const getPost = id => {\n/* ... */\n};\n\n// ✅ Good - Break circular dependency\n// user.js\nexport const getUser = id => {\n/* ... */\n};\n\n// post.js\nexport const getPost = id => {\n/* ... */\n};\n\n// user-post.js - Common module\nimport { getUser } from './user.js';\nimport { getPost } from './post.js';\n\nexport const getUserWithPosts = async userId => {\nconst user = await getUser(userId);\nconst posts = await getPost(userId);\nreturn { user, posts };\n};\n\n**Dynamic Imports and Code Splitting:**\n\n// Static import - included in main bundle\nimport Header from './Header';\n\n// Dynamic import - creates separate chunk\nconst LazyComponent = React.lazy(() => import('./LazyComponent'));\n\n// Dynamic import with webpack magic comments\nconst LazyComponent = React.lazy(\n() => import(/* webpackChunkName: \"lazy-component\" */ './LazyComponent')\n);\n\n// Multiple dynamic imports\nconst loadComponent = componentName => {\nreturn import(`./components/${componentName}`);\n};\n\n**Webpack Module Resolution:**\n\n// webpack.config.js\nmodule.exports = {\nresolve: {\n// File extensions to resolve\nextensions: ['.js', '.jsx', '.ts', '.tsx'],\n\n// Directory names to resolve\nmodules: ['node_modules', 'src'],\n\n// Alias for shorter imports\nalias: {\n'@': path.resolve(__dirname, 'src'),\n'@components': path.resolve(__dirname, 'src/components'),\n'@utils': path.resolve(__dirname, 'src/utils'),\n},\n},\n};\n\n// Usage with aliases\nimport Header from '@components/Header';\nimport { formatDate } from '@utils/date';\n\n**Dependency Graph Optimization:**\n\n// webpack.config.js\nmodule.exports = {\noptimization: {\n// Split chunks based on dependency graph\nsplitChunks: {\nchunks: 'all',\ncacheGroups: {\n// Vendor chunk for node_modules\nvendor: {\ntest: /[\\\\/]node_modules[\\\\/]/,\nname: 'vendors',\nchunks: 'all',\n},\n\n// Common chunk for shared code\ncommon: {\nname: 'common',\nminChunks: 2,\nchunks: 'all',\nenforce: true,\n},\n},\n},\n},\n};\n\n**Webpack Stats and Analysis:**\n\n// webpack.config.js\nmodule.exports = {\nstats: {\n// Show module information\nmodules: true,\n\n// Show chunk information\nchunks: true,\n\n// Show dependency information\ndependencies: true,\n\n// Show reasons for including modules\nreasons: true,\n},\n};\n\n// Generate stats file\n// webpack --config webpack.config.js --json > stats.json",
      "content": "What is a dependency graph in Webpack?",
      "learningPaths": [
        "deployment-devops"
      ],
      "title": "Webpack Dependency Graph",
      "codeBlock": "// Entry point: src/index.js\nimport React from 'react';\nimport ReactDOM from 'react-dom';\nimport App from './App';\nimport './styles.css';\n\nReactDOM.render(<App />, document.getElementById('root'));\n\n// App.js\nimport Header from './components/Header';\nimport Main from './components/Main';\nimport Footer from './components/Footer';\n\nexport default function App() {\n  return (\n    <div>\n      <Header />\n      <Main />\n      <Footer />\n    </div>\n  );\n}\n\n// Header.js\nimport Logo from './Logo';\nimport Navigation from './Navigation';\n\nexport default function Header() {\n  return (\n    <header>\n      <Logo />\n      <Navigation />\n    </header>\n  );\n}",
      "topics": [
        "Docker",
        "CI/CD",
        "AWS",
        "Build Tools"
      ]
    },
    {
      "id": "imported-deployment-devops-1759191594555-4",
      "createdAt": "2025-09-30T00:19:54.627Z",
      "isActive": true,
      "options": [],
      "title": "Monitoring and Logging",
      "importedAt": "2025-09-30T00:19:54.555Z",
      "codeBlock": "// Prometheus metrics\nconst prometheus = require('prom-client');\n\n// Create metrics\nconst httpRequestDuration = new prometheus.Histogram({\n  name: 'http_request_duration_seconds',\n  help: 'Duration of HTTP requests in seconds',\n  labelNames: ['method', 'route', 'status_code'],\n  buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10],\n});\n\nconst httpRequestTotal = new prometheus.Counter({\n  name: 'http_requests_total',\n  help: 'Total number of HTTP requests',\n  labelNames: ['method', 'route', 'status_code'],\n});\n\nconst activeConnections = new prometheus.Gauge({\n  name: 'active_connections',\n  help: 'Number of active connections',\n});\n\n// Middleware to collect metrics\nfunction metricsMiddleware(req, res, next) {\n  const start = Date.now();\n\n  res.on('finish', () => {\n    const duration = (Date.now() - start) / 1000;\n    const labels = {\n      method: req.method,\n      route: req.route?.path || req.path,\n      status_code: res.statusCode,\n    };\n\n    httpRequestDuration.observe(labels, duration);\n    httpRequestTotal.inc(labels);\n  });\n\n  next();\n}\n\n// Health check endpoint\napp.get('/health', (req, res) => {\n  res.json({\n    status: 'healthy',\n    timestamp: new Date().toISOString(),\n    uptime: process.uptime(),\n    memory: process.memoryUsage(),\n    version: process.env.npm_package_version,\n  });\n});\n\n// Metrics endpoint\napp.get('/metrics', (req, res) => {\n  res.set('Content-Type', prometheus.register.contentType);\n  res.end(prometheus.register.metrics());\n});",
      "content": "Explain monitoring and logging strategies for production applications.",
      "correctAnswer": null,
      "topics": [
        "Docker",
        "CI/CD",
        "AWS",
        "Build Tools"
      ],
      "learningPaths": [
        "deployment-devops"
      ],
      "difficulty": "intermediate",
      "source": "QuestionsBank",
      "explanation": "**1. Application Monitoring:**\n\n// Prometheus metrics\nconst prometheus = require('prom-client');\n\n// Create metrics\nconst httpRequestDuration = new prometheus.Histogram({\nname: 'http_request_duration_seconds',\nhelp: 'Duration of HTTP requests in seconds',\nlabelNames: ['method', 'route', 'status_code'],\nbuckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10],\n});\n\nconst httpRequestTotal = new prometheus.Counter({\nname: 'http_requests_total',\nhelp: 'Total number of HTTP requests',\nlabelNames: ['method', 'route', 'status_code'],\n});\n\nconst activeConnections = new prometheus.Gauge({\nname: 'active_connections',\nhelp: 'Number of active connections',\n});\n\n// Middleware to collect metrics\nfunction metricsMiddleware(req, res, next) {\nconst start = Date.now();\n\nres.on('finish', () => {\nconst duration = (Date.now() - start) / 1000;\nconst labels = {\nmethod: req.method,\nroute: req.route?.path || req.path,\nstatus_code: res.statusCode,\n};\n\nhttpRequestDuration.observe(labels, duration);\nhttpRequestTotal.inc(labels);\n});\n\nnext();\n}\n\n// Health check endpoint\napp.get('/health', (req, res) => {\nres.json({\nstatus: 'healthy',\ntimestamp: new Date().toISOString(),\nuptime: process.uptime(),\nmemory: process.memoryUsage(),\nversion: process.env.npm_package_version,\n});\n});\n\n// Metrics endpoint\napp.get('/metrics', (req, res) => {\nres.set('Content-Type', prometheus.register.contentType);\nres.end(prometheus.register.metrics());\n});\n\n**2. Logging Strategy:**\n\n// Winston logger configuration\nconst winston = require('winston');\nconst { combine, timestamp, errors, json, printf, colorize } = winston.format;\n\n// Custom format\nconst logFormat = printf(({ level, message, timestamp, stack, ...meta }) => {\nreturn `${timestamp} [${level}]: ${stack || message} ${Object.keys(meta).length ? JSON.stringify(meta) : ''}`;\n});\n\n// Create logger\nconst logger = winston.createLogger({\nlevel: process.env.LOG_LEVEL || 'info',\nformat: combine(timestamp(), errors({ stack: true }), json()),\ndefaultMeta: {\nservice: 'web-app',\nversion: process.env.npm_package_version,\nenvironment: process.env.NODE_ENV,\n},\ntransports: [\n// Console transport\nnew winston.transports.Console({\nformat: combine(colorize(), timestamp(), logFormat),\n}),\n\n// File transport for errors\nnew winston.transports.File({\nfilename: 'logs/error.log',\nlevel: 'error',\nmaxsize: 5242880, // 5MB\nmaxFiles: 5,\n}),\n\n// File transport for all logs\nnew winston.transports.File({\nfilename: 'logs/combined.log',\nmaxsize: 5242880, // 5MB\nmaxFiles: 5,\n}),\n],\n});\n\n// Request logging middleware\nfunction requestLogger(req, res, next) {\nconst start = Date.now();\n\nres.on('finish', () => {\nconst duration = Date.now() - start;\nconst logData = {\nmethod: req.method,\nurl: req.url,\nstatusCode: res.statusCode,\nduration: `${duration}ms`,\nuserAgent: req.get('User-Agent'),\nip: req.ip,\nuserId: req.user?.id,\n};\n\nif (res.statusCode >= 400) {\nlogger.error('HTTP Request', logData);\n} else {\nlogger.info('HTTP Request', logData);\n}\n});\n\nnext();\n}\n\n// Error logging\nfunction errorLogger(err, req, res, next) {\nlogger.error('Unhandled Error', {\nerror: err.message,\nstack: err.stack,\nurl: req.url,\nmethod: req.method,\nip: req.ip,\nuserAgent: req.get('User-Agent'),\nuserId: req.user?.id,\n});\n\nnext(err);\n}\n\n**3. ELK Stack Configuration:**\n\n# docker-compose.elk.yml\nversion: '3.8'\n\nservices:\nelasticsearch:\nimage: docker.elastic.co/elasticsearch/elasticsearch:8.11.0\nenvironment:\n- discovery.type=single-node\n- xpack.security.enabled=false\n- 'ES_JAVA_OPTS=-Xms512m -Xmx512m'\nports:\n- '9200:9200'\nvolumes:\n- elasticsearch_data:/usr/share/elasticsearch/data\nnetworks:\n- elk\n\nlogstash:\nimage: docker.elastic.co/logstash/logstash:8.11.0\nvolumes:\n- ./logstash/pipeline:/usr/share/logstash/pipeline\n- ./logstash/config:/usr/share/logstash/config\nports:\n- '5044:5044'\n- '5000:5000/tcp'\n- '5000:5000/udp'\n- '9600:9600'\nenvironment:\nLS_JAVA_OPTS: '-Xmx256m -Xms256m'\nnetworks:\n- elk\ndepends_on:\n- elasticsearch\n\nkibana:\nimage: docker.elastic.co/kibana/kibana:8.11.0\nports:\n- '5601:5601'\nenvironment:\nELASTICSEARCH_HOSTS: http://elasticsearch:9200\nnetworks:\n- elk\ndepends_on:\n- elasticsearch\n\nfilebeat:\nimage: docker.elastic.co/beats/filebeat:8.11.0\nuser: root\nvolumes:\n- ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro\n- ./logs:/var/log/app:ro\n- /var/lib/docker/containers:/var/lib/docker/containers:ro\n- /var/run/docker.sock:/var/run/docker.sock:ro\nnetworks:\n- elk\ndepends_on:\n- logstash\n\nvolumes:\nelasticsearch_data:\n\nnetworks:\nelk:\ndriver: bridge",
      "isComplete": false,
      "updatedAt": "2025-09-30T00:19:54.627Z",
      "category": "Deployment & DevOps",
      "type": "code"
    },
    {
      "id": "imported-deployment-devops-1759191594556-6",
      "content": "What is Webpack, and what is it used for?",
      "type": "code",
      "createdAt": "2025-09-30T00:19:54.627Z",
      "options": [],
      "source": "QuestionsBank",
      "learningPaths": [
        "deployment-devops"
      ],
      "codeBlock": "// webpack.config.js\nconst path = require('path');\nconst HtmlWebpackPlugin = require('html-webpack-plugin');\n\nmodule.exports = {\n  entry: './src/index.js',\n  output: {\n    path: path.resolve(__dirname, 'dist'),\n    filename: 'bundle.[contenthash].js',\n    clean: true,\n  },\n  module: {\n    rules: [\n      {\n        test: /\\.js$/,\n        exclude: /node_modules/,\n        use: {\n          loader: 'babel-loader',\n          options: {\n            presets: ['@babel/preset-env', '@babel/preset-react'],\n          },\n        },\n      },\n      {\n        test: /\\.css$/,\n        use: ['style-loader', 'css-loader'],\n      },\n      {\n        test: /\\.(png|svg|jpg|jpeg|gif)$/i,\n        type: 'asset/resource',\n      },\n    ],\n  },\n  plugins: [\n    new HtmlWebpackPlugin({\n      template: './src/index.html',\n    }),\n  ],\n  resolve: {\n    extensions: ['.js', '.jsx', '.ts', '.tsx'],\n  },\n};",
      "isActive": true,
      "title": "Webpack Module Bundler",
      "category": "Deployment & DevOps",
      "correctAnswer": null,
      "isComplete": false,
      "explanation": "Webpack is a module bundler. Its primary purpose is to take multiple JavaScript files (and other assets like CSS, images) that use modules (import/export) and bundle them into a smaller number of optimized files (often just one) for the browser. This is necessary because browsers historically couldn't natively handle complex module dependency graphs.\n\n**Basic Webpack Configuration:**\n\n// webpack.config.js\nconst path = require('path');\nconst HtmlWebpackPlugin = require('html-webpack-plugin');\n\nmodule.exports = {\nentry: './src/index.js',\noutput: {\npath: path.resolve(__dirname, 'dist'),\nfilename: 'bundle.[contenthash].js',\nclean: true,\n},\nmodule: {\nrules: [\n{\ntest: /\\.js$/,\nexclude: /node_modules/,\nuse: {\nloader: 'babel-loader',\noptions: {\npresets: ['@babel/preset-env', '@babel/preset-react'],\n},\n},\n},\n{\ntest: /\\.css$/,\nuse: ['style-loader', 'css-loader'],\n},\n{\ntest: /\\.(png|svg|jpg|jpeg|gif)$/i,\ntype: 'asset/resource',\n},\n],\n},\nplugins: [\nnew HtmlWebpackPlugin({\ntemplate: './src/index.html',\n}),\n],\nresolve: {\nextensions: ['.js', '.jsx', '.ts', '.tsx'],\n},\n};\n\n**Webpack Loaders:**\n\n// Different loaders for different file types\nmodule.exports = {\nmodule: {\nrules: [\n// JavaScript/TypeScript\n{\ntest: /\\.(js|jsx|ts|tsx)$/,\nexclude: /node_modules/,\nuse: {\nloader: 'babel-loader',\noptions: {\npresets: [\n'@babel/preset-env',\n'@babel/preset-react',\n'@babel/preset-typescript',\n],\n},\n},\n},\n\n// CSS\n{\ntest: /\\.css$/,\nuse: [\n'style-loader', // Injects CSS into DOM\n'css-loader', // Resolves CSS imports\n'postcss-loader', // PostCSS processing\n],\n},\n\n// SCSS/Sass\n{\ntest: /\\.(scss|sass)$/,\nuse: ['style-loader', 'css-loader', 'sass-loader'],\n},\n\n// Images\n{\ntest: /\\.(png|jpe?g|gif|svg)$/i,\ntype: 'asset/resource',\ngenerator: {\nfilename: 'images/[name].[hash][ext]',\n},\n},\n\n// Fonts\n{\ntest: /\\.(woff|woff2|eot|ttf|otf)$/i,\ntype: 'asset/resource',\ngenerator: {\nfilename: 'fonts/[name].[hash][ext]',\n},\n},\n],\n},\n};\n\n**Webpack Plugins:**\n\nconst HtmlWebpackPlugin = require('html-webpack-plugin');\nconst MiniCssExtractPlugin = require('mini-css-extract-plugin');\nconst { CleanWebpackPlugin } = require('clean-webpack-plugin');\nconst CopyWebpackPlugin = require('copy-webpack-plugin');\n\nmodule.exports = {\nplugins: [\n// Clean dist folder before build\nnew CleanWebpackPlugin(),\n\n// Generate HTML file\nnew HtmlWebpackPlugin({\ntemplate: './src/index.html',\ntitle: 'My App',\nmeta: {\nviewport: 'width=device-width, initial-scale=1',\n},\n}),\n\n// Extract CSS to separate file\nnew MiniCssExtractPlugin({\nfilename: 'styles.[contenthash].css',\n}),\n\n// Copy static assets\nnew CopyWebpackPlugin({\npatterns: [{ from: 'public', to: 'assets' }],\n}),\n],\n};\n\n**Code Splitting:**\n\nmodule.exports = {\noptimization: {\nsplitChunks: {\nchunks: 'all',\ncacheGroups: {\nvendor: {\ntest: /[\\\\/]node_modules[\\\\/]/,\nname: 'vendors',\nchunks: 'all',\n},\ncommon: {\nname: 'common',\nminChunks: 2,\nchunks: 'all',\nenforce: true,\n},\n},\n},\n},\n};\n\n// Dynamic imports for code splitting\n// In your JavaScript code:\nconst LazyComponent = React.lazy(() => import('./LazyComponent'));\n\n// Or with webpack magic comments:\nconst LazyComponent = React.lazy(\n() => import(/* webpackChunkName: \"lazy-component\" */ './LazyComponent')\n);\n\n**Development vs Production:**\n\n// webpack.config.js\nconst isProduction = process.env.NODE_ENV === 'production';\n\nmodule.exports = {\nmode: isProduction ? 'production' : 'development',\n\ndevtool: isProduction ? 'source-map' : 'eval-source-map',\n\ndevServer: {\nstatic: './dist',\nhot: true,\nopen: true,\nport: 3000,\nhistoryApiFallback: true,\n},\n\noptimization: {\nminimize: isProduction,\nsplitChunks: isProduction\n? {\nchunks: 'all',\n}\n: false,\n},\n\nplugins: [\n...(isProduction\n? [new MiniCssExtractPlugin(), new TerserPlugin()]\n: [new webpack.HotModuleReplacementPlugin()]),\n],\n};",
      "difficulty": "intermediate",
      "topics": [
        "Docker",
        "CI/CD",
        "AWS",
        "Build Tools"
      ],
      "importedAt": "2025-09-30T00:19:54.556Z",
      "updatedAt": "2025-09-30T00:19:54.627Z"
    },
    {
      "id": "imported-deployment-devops-1759191594555-3",
      "difficulty": "intermediate",
      "learningPaths": [
        "deployment-devops"
      ],
      "isComplete": false,
      "updatedAt": "2025-09-30T00:19:54.627Z",
      "options": [],
      "createdAt": "2025-09-30T00:19:54.627Z",
      "correctAnswer": null,
      "explanation": "**1. Terraform Configuration:**\n\n# main.tf\nterraform {\nrequired_version = \">= 1.0\"\nrequired_providers {\naws = {\nsource  = \"hashicorp/aws\"\nversion = \"~> 5.0\"\n}\n}\n\nbackend \"s3\" {\nbucket = \"my-terraform-state\"\nkey    = \"production/terraform.tfstate\"\nregion = \"us-west-2\"\n}\n}\n\nprovider \"aws\" {\nregion = var.aws_region\n}\n\n# VPC Configuration\nresource \"aws_vpc\" \"main\" {\ncidr_block           = \"10.0.0.0/16\"\nenable_dns_hostnames = true\nenable_dns_support   = true\n\ntags = {\nName = \"${var.project_name}-vpc\"\n}\n}\n\nresource \"aws_internet_gateway\" \"main\" {\nvpc_id = aws_vpc.main.id\n\ntags = {\nName = \"${var.project_name}-igw\"\n}\n}\n\n# Subnets\nresource \"aws_subnet\" \"public\" {\ncount = length(var.availability_zones)\n\nvpc_id                  = aws_vpc.main.id\ncidr_block              = \"10.0.${count.index + 1}.0/24\"\navailability_zone       = var.availability_zones[count.index]\nmap_public_ip_on_launch = true\n\ntags = {\nName = \"${var.project_name}-public-subnet-${count.index + 1}\"\n}\n}\n\nresource \"aws_subnet\" \"private\" {\ncount = length(var.availability_zones)\n\nvpc_id            = aws_vpc.main.id\ncidr_block        = \"10.0.${count.index + 10}.0/24\"\navailability_zone = var.availability_zones[count.index]\n\ntags = {\nName = \"${var.project_name}-private-subnet-${count.index + 1}\"\n}\n}\n\n# EKS Cluster\nresource \"aws_eks_cluster\" \"main\" {\nname     = \"${var.project_name}-cluster\"\nrole_arn = aws_iam_role.eks_cluster.arn\nversion  = var.kubernetes_version\n\nvpc_config {\nsubnet_ids = aws_subnet.private[*].id\n}\n\ndepends_on = [\naws_iam_role_policy_attachment.eks_cluster_policy,\naws_iam_role_policy_attachment.eks_vpc_resource_controller,\n]\n\ntags = {\nName = \"${var.project_name}-cluster\"\n}\n}\n\n# RDS Database\nresource \"aws_db_subnet_group\" \"main\" {\nname       = \"${var.project_name}-db-subnet-group\"\nsubnet_ids = aws_subnet.private[*].id\n\ntags = {\nName = \"${var.project_name}-db-subnet-group\"\n}\n}\n\nresource \"aws_db_instance\" \"main\" {\nidentifier = \"${var.project_name}-db\"\n\nengine         = \"postgres\"\nengine_version = \"15.4\"\ninstance_class = var.db_instance_class\n\nallocated_storage     = 20\nmax_allocated_storage = 100\nstorage_encrypted     = true\n\ndb_name  = var.db_name\nusername = var.db_username\npassword = var.db_password\n\nvpc_security_group_ids = [aws_security_group.rds.id]\ndb_subnet_group_name   = aws_db_subnet_group.main.name\n\nbackup_retention_period = 7\nbackup_window          = \"03:00-04:00\"\nmaintenance_window     = \"sun:04:00-sun:05:00\"\n\nskip_final_snapshot = false\nfinal_snapshot_identifier = \"${var.project_name}-db-final-snapshot-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\"\n\ntags = {\nName = \"${var.project_name}-db\"\n}\n}\n\n**2. CloudFormation Template:**\n\n# cloudformation.yaml\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: 'Production infrastructure for web application'\n\nParameters:\nProjectName:\nType: String\nDefault: myapp\nDescription: Name of the project\n\nEnvironment:\nType: String\nDefault: production\nAllowedValues: [development, staging, production]\nDescription: Environment name\n\nInstanceType:\nType: String\nDefault: t3.medium\nAllowedValues: [t3.small, t3.medium, t3.large]\nDescription: EC2 instance type\n\nResources:\n# VPC\nVPC:\nType: AWS::EC2::VPC\nProperties:\nCidrBlock: 10.0.0.0/16\nEnableDnsHostnames: true\nEnableDnsSupport: true\nTags:\n- Key: Name\nValue: !Sub '${ProjectName}-${Environment}-vpc'\n\n# Internet Gateway\nInternetGateway:\nType: AWS::EC2::InternetGateway\nProperties:\nTags:\n- Key: Name\nValue: !Sub '${ProjectName}-${Environment}-igw'\n\nInternetGatewayAttachment:\nType: AWS::EC2::VPCGatewayAttachment\nProperties:\nInternetGatewayId: !Ref InternetGateway\nVpcId: !Ref VPC\n\n# Public Subnets\nPublicSubnet1:\nType: AWS::EC2::Subnet\nProperties:\nVpcId: !Ref VPC\nAvailabilityZone: !Select [0, !GetAZs '']\nCidrBlock: 10.0.1.0/24\nMapPublicIpOnLaunch: true\nTags:\n- Key: Name\nValue: !Sub '${ProjectName}-${Environment}-public-subnet-1'\n\nPublicSubnet2:\nType: AWS::EC2::Subnet\nProperties:\nVpcId: !Ref VPC\nAvailabilityZone: !Select [1, !GetAZs '']\nCidrBlock: 10.0.2.0/24\nMapPublicIpOnLaunch: true\nTags:\n- Key: Name\nValue: !Sub '${ProjectName}-${Environment}-public-subnet-2'\n\n# Private Subnets\nPrivateSubnet1:\nType: AWS::EC2::Subnet\nProperties:\nVpcId: !Ref VPC\nAvailabilityZone: !Select [0, !GetAZs '']\nCidrBlock: 10.0.10.0/24\nTags:\n- Key: Name\nValue: !Sub '${ProjectName}-${Environment}-private-subnet-1'\n\nPrivateSubnet2:\nType: AWS::EC2::Subnet\nProperties:\nVpcId: !Ref VPC\nAvailabilityZone: !Select [1, !GetAZs '']\nCidrBlock: 10.0.20.0/24\nTags:\n- Key: Name\nValue: !Sub '${ProjectName}-${Environment}-private-subnet-2'\n\n# EKS Cluster\nEKSCluster:\nType: AWS::EKS::Cluster\nProperties:\nName: !Sub '${ProjectName}-${Environment}-cluster'\nVersion: '1.28'\nRoleArn: !GetAtt EKSClusterRole.Arn\nResourcesVpcConfig:\nSubnetIds:\n- !Ref PrivateSubnet1\n- !Ref PrivateSubnet2\nSecurityGroupIds:\n- !Ref EKSClusterSecurityGroup\nLogging:\nClusterLogging:\nEnabledTypes:\n- Type: api\n- Type: audit\n- Type: authenticator\n- Type: controllerManager\n- Type: scheduler\n\n# RDS Database\nDBSubnetGroup:\nType: AWS::RDS::DBSubnetGroup\nProperties:\nDBSubnetGroupDescription: !Sub '${ProjectName}-${Environment}-db-subnet-group'\nSubnetIds:\n- !Ref PrivateSubnet1\n- !Ref PrivateSubnet2\nTags:\n- Key: Name\nValue: !Sub '${ProjectName}-${Environment}-db-subnet-group'\n\nDatabase:\nType: AWS::RDS::DBInstance\nProperties:\nDBInstanceIdentifier: !Sub '${ProjectName}-${Environment}-db'\nDBName: !Ref DBName\nDBInstanceClass: !Ref DBInstanceClass\nEngine: postgres\nEngineVersion: '15.4'\nMasterUsername: !Ref DBUsername\nMasterUserPassword: !Ref DBPassword\nAllocatedStorage: 20\nMaxAllocatedStorage: 100\nStorageEncrypted: true\nVPCSecurityGroups:\n- !Ref DatabaseSecurityGroup\nDBSubnetGroupName: !Ref DBSubnetGroup\nBackupRetentionPeriod: 7\nPreferredBackupWindow: '03:00-04:00'\nPreferredMaintenanceWindow: 'sun:04:00-sun:05:00'\nTags:\n- Key: Name\nValue: !Sub '${ProjectName}-${Environment}-db'\n\nOutputs:\nVPCId:\nDescription: VPC ID\nValue: !Ref VPC\nExport:\nName: !Sub '${ProjectName}-${Environment}-VPC-ID'\n\nEKSClusterName:\nDescription: EKS Cluster Name\nValue: !Ref EKSCluster\nExport:\nName: !Sub '${ProjectName}-${Environment}-EKS-Cluster-Name'\n\nDatabaseEndpoint:\nDescription: RDS Database Endpoint\nValue: !GetAtt Database.Endpoint.Address\nExport:\nName: !Sub '${ProjectName}-${Environment}-Database-Endpoint'",
      "codeBlock": "# main.tf\nterraform {\n  required_version = \">= 1.0\"\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n\n  backend \"s3\" {\n    bucket = \"my-terraform-state\"\n    key    = \"production/terraform.tfstate\"\n    region = \"us-west-2\"\n  }\n}\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n\n# VPC Configuration\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"${var.project_name}-vpc\"\n  }\n}\n\nresource \"aws_internet_gateway\" \"main\" {\n  vpc_id = aws_vpc.main.id\n\n  tags = {\n    Name = \"${var.project_name}-igw\"\n  }\n}\n\n# Subnets\nresource \"aws_subnet\" \"public\" {\n  count = length(var.availability_zones)\n\n  vpc_id                  = aws_vpc.main.id\n  cidr_block              = \"10.0.${count.index + 1}.0/24\"\n  availability_zone       = var.availability_zones[count.index]\n  map_public_ip_on_launch = true\n\n  tags = {\n    Name = \"${var.project_name}-public-subnet-${count.index + 1}\"\n  }\n}\n\nresource \"aws_subnet\" \"private\" {\n  count = length(var.availability_zones)\n\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.${count.index + 10}.0/24\"\n  availability_zone = var.availability_zones[count.index]\n\n  tags = {\n    Name = \"${var.project_name}-private-subnet-${count.index + 1}\"\n  }\n}\n\n# EKS Cluster\nresource \"aws_eks_cluster\" \"main\" {\n  name     = \"${var.project_name}-cluster\"\n  role_arn = aws_iam_role.eks_cluster.arn\n  version  = var.kubernetes_version\n\n  vpc_config {\n    subnet_ids = aws_subnet.private[*].id\n  }\n\n  depends_on = [\n    aws_iam_role_policy_attachment.eks_cluster_policy,\n    aws_iam_role_policy_attachment.eks_vpc_resource_controller,\n  ]\n\n  tags = {\n    Name = \"${var.project_name}-cluster\"\n  }\n}\n\n# RDS Database\nresource \"aws_db_subnet_group\" \"main\" {\n  name       = \"${var.project_name}-db-subnet-group\"\n  subnet_ids = aws_subnet.private[*].id\n\n  tags = {\n    Name = \"${var.project_name}-db-subnet-group\"\n  }\n}\n\nresource \"aws_db_instance\" \"main\" {\n  identifier = \"${var.project_name}-db\"\n\n  engine         = \"postgres\"\n  engine_version = \"15.4\"\n  instance_class = var.db_instance_class\n\n  allocated_storage     = 20\n  max_allocated_storage = 100\n  storage_encrypted     = true\n\n  db_name  = var.db_name\n  username = var.db_username\n  password = var.db_password\n\n  vpc_security_group_ids = [aws_security_group.rds.id]\n  db_subnet_group_name   = aws_db_subnet_group.main.name\n\n  backup_retention_period = 7\n  backup_window          = \"03:00-04:00\"\n  maintenance_window     = \"sun:04:00-sun:05:00\"\n\n  skip_final_snapshot = false\n  final_snapshot_identifier = \"${var.project_name}-db-final-snapshot-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\"\n\n  tags = {\n    Name = \"${var.project_name}-db\"\n  }\n}",
      "content": "Explain Infrastructure as Code (IaC) with Terraform and CloudFormation.",
      "type": "code",
      "isActive": true,
      "source": "QuestionsBank",
      "topics": [
        "Docker",
        "CI/CD",
        "AWS",
        "Build Tools"
      ],
      "category": "Deployment & DevOps",
      "importedAt": "2025-09-30T00:19:54.555Z",
      "title": "Infrastructure as Code"
    },
    {
      "id": "imported-deployment-devops-1759191594556-7",
      "isComplete": false,
      "content": "What is tree shaking?",
      "explanation": "Tree shaking is a dead code elimination process performed by bundlers like Webpack. It analyzes your code and its module dependencies to identify and remove code that is not actually used (exported but never imported). This significantly reduces the final bundle size. It works best with ES6 module syntax (import/export) due to its static structure.\n\n**How Tree Shaking Works:**\n\n// math.js - Library with multiple exports\nexport function add(a, b) {\nreturn a + b;\n}\n\nexport function subtract(a, b) {\nreturn a - b;\n}\n\nexport function multiply(a, b) {\nreturn a * b;\n}\n\nexport function divide(a, b) {\nreturn a / b;\n}\n\n// main.js - Only imports what it uses\nimport { add, multiply } from './math.js';\n\nconsole.log(add(2, 3)); // 5\nconsole.log(multiply(4, 5)); // 20\n\n// After tree shaking, only add() and multiply() are included in the bundle\n// subtract() and divide() are eliminated\n\n**ES6 Modules (Tree Shakeable):**\n\n// ✅ Good - ES6 modules (tree shakeable)\n// utils.js\nexport const formatDate = date => {\n/* ... */\n};\nexport const formatCurrency = amount => {\n/* ... */\n};\nexport const validateEmail = email => {\n/* ... */\n};\n\n// main.js\nimport { formatDate } from './utils.js';\n// Only formatDate is included in bundle\n\n// ❌ Bad - CommonJS (not tree shakeable)\n// utils.js\nmodule.exports = {\nformatDate: date => {\n/* ... */\n},\nformatCurrency: amount => {\n/* ... */\n},\nvalidateEmail: email => {\n/* ... */\n},\n};\n\n// main.js\nconst { formatDate } = require('./utils.js');\n// All functions are included in bundle\n\n**Tree Shaking with Libraries:**\n\n// ✅ Good - Import specific functions\nimport { debounce, throttle } from 'lodash-es';\n\n// ❌ Bad - Import entire library\nimport _ from 'lodash';\n\n// ✅ Good - Import from specific path\nimport debounce from 'lodash/debounce';\n\n// ❌ Bad - Import from main entry\nimport { debounce } from 'lodash';\n\n**Webpack Tree Shaking Configuration:**\n\n// webpack.config.js\nmodule.exports = {\nmode: 'production', // Tree shaking only works in production mode\n\noptimization: {\nusedExports: true, // Mark used exports\nsideEffects: false, // Assume no side effects\n\n// Or specify files with side effects\nsideEffects: ['*.css', '*.scss', './src/polyfills.js'],\n},\n};\n\n**Package.json Side Effects:**\n\n{\n\"name\": \"my-package\",\n\"sideEffects\": false,\n// or\n\"sideEffects\": [\"*.css\", \"*.scss\", \"./src/polyfills.js\"]\n}\n\n**Tree Shaking with CSS:**\n\n// webpack.config.js\nconst MiniCssExtractPlugin = require('mini-css-extract-plugin');\nconst PurgeCSSPlugin = require('purgecss-webpack-plugin');\n\nmodule.exports = {\nmodule: {\nrules: [\n{\ntest: /\\.css$/,\nuse: [MiniCssExtractPlugin.loader, 'css-loader'],\n},\n],\n},\n\nplugins: [\nnew MiniCssExtractPlugin(),\n\n// Remove unused CSS\nnew PurgeCSSPlugin({\npaths: glob.sync(`${PATHS.src}/**/*`, { nodir: true }),\nsafelist: {\nstandard: [/^hljs/, /^cm-/, /^CodeMirror/],\n},\n}),\n],\n};\n\n**Tree Shaking Best Practices:**\n\n// ✅ Good - Pure functions (tree shakeable)\nexport const utils = {\nadd: (a, b) => a + b,\nmultiply: (a, b) => a * b,\n};\n\n// ❌ Bad - Side effects (not tree shakeable)\nexport const utils = {\nadd: (a, b) => {\nconsole.log('Adding numbers'); // Side effect\nreturn a + b;\n},\n};\n\n// ✅ Good - Separate exports\nexport const formatDate = date => {\n/* ... */\n};\nexport const formatCurrency = amount => {\n/* ... */\n};\n\n// ❌ Bad - Object export\nexport const formatters = {\ndate: date => {\n/* ... */\n},\ncurrency: amount => {\n/* ... */\n},\n};",
      "correctAnswer": null,
      "learningPaths": [
        "deployment-devops"
      ],
      "codeBlock": "// math.js - Library with multiple exports\nexport function add(a, b) {\n  return a + b;\n}\n\nexport function subtract(a, b) {\n  return a - b;\n}\n\nexport function multiply(a, b) {\n  return a * b;\n}\n\nexport function divide(a, b) {\n  return a / b;\n}\n\n// main.js - Only imports what it uses\nimport { add, multiply } from './math.js';\n\nconsole.log(add(2, 3)); // 5\nconsole.log(multiply(4, 5)); // 20\n\n// After tree shaking, only add() and multiply() are included in the bundle\n// subtract() and divide() are eliminated",
      "topics": [
        "Docker",
        "CI/CD",
        "AWS",
        "Build Tools"
      ],
      "title": "Tree Shaking",
      "updatedAt": "2025-09-30T00:19:54.627Z",
      "category": "Deployment & DevOps",
      "importedAt": "2025-09-30T00:19:54.556Z",
      "type": "code",
      "options": [],
      "isActive": true,
      "createdAt": "2025-09-30T00:19:54.627Z",
      "difficulty": "intermediate",
      "source": "QuestionsBank"
    },
    {
      "id": "imported-deployment-devops-1759191594554-1",
      "options": [],
      "type": "code",
      "topics": [
        "Docker",
        "CI/CD",
        "AWS",
        "Build Tools"
      ],
      "source": "QuestionsBank",
      "title": "Kubernetes Deployment",
      "isActive": true,
      "codeBlock": "# deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\n  labels:\n    app: web-app\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: web-app\n  template:\n    metadata:\n      labels:\n        app: web-app\n    spec:\n      containers:\n        - name: web-app\n          image: myapp:latest\n          ports:\n            - containerPort: 3000\n          env:\n            - name: NODE_ENV\n              value: 'production'\n            - name: DATABASE_URL\n              valueFrom:\n                secretKeyRef:\n                  name: app-secrets\n                  key: database-url\n          resources:\n            requests:\n              memory: '256Mi'\n              cpu: '250m'\n            limits:\n              memory: '512Mi'\n              cpu: '500m'\n          livenessProbe:\n            httpGet:\n              path: /health\n              port: 3000\n            initialDelaySeconds: 30\n            periodSeconds: 10\n          readinessProbe:\n            httpGet:\n              path: /ready\n              port: 3000\n            initialDelaySeconds: 5\n            periodSeconds: 5\n          volumeMounts:\n            - name: app-logs\n              mountPath: /app/logs\n      volumes:\n        - name: app-logs\n          emptyDir: {}\n      imagePullSecrets:\n        - name: registry-secret",
      "category": "Deployment & DevOps",
      "createdAt": "2025-09-30T00:19:54.627Z",
      "isComplete": false,
      "correctAnswer": null,
      "learningPaths": [
        "deployment-devops"
      ],
      "difficulty": "intermediate",
      "updatedAt": "2025-09-30T00:19:54.627Z",
      "importedAt": "2025-09-30T00:19:54.554Z",
      "explanation": "**1. Kubernetes Deployment:**\n\n# deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: web-app\nlabels:\napp: web-app\nspec:\nreplicas: 3\nselector:\nmatchLabels:\napp: web-app\ntemplate:\nmetadata:\nlabels:\napp: web-app\nspec:\ncontainers:\n- name: web-app\nimage: myapp:latest\nports:\n- containerPort: 3000\nenv:\n- name: NODE_ENV\nvalue: 'production'\n- name: DATABASE_URL\nvalueFrom:\nsecretKeyRef:\nname: app-secrets\nkey: database-url\nresources:\nrequests:\nmemory: '256Mi'\ncpu: '250m'\nlimits:\nmemory: '512Mi'\ncpu: '500m'\nlivenessProbe:\nhttpGet:\npath: /health\nport: 3000\ninitialDelaySeconds: 30\nperiodSeconds: 10\nreadinessProbe:\nhttpGet:\npath: /ready\nport: 3000\ninitialDelaySeconds: 5\nperiodSeconds: 5\nvolumeMounts:\n- name: app-logs\nmountPath: /app/logs\nvolumes:\n- name: app-logs\nemptyDir: {}\nimagePullSecrets:\n- name: registry-secret\n\n**2. Service Configuration:**\n\n# service.yaml\napiVersion: v1\nkind: Service\nmetadata:\nname: web-app-service\nspec:\nselector:\napp: web-app\nports:\n- protocol: TCP\nport: 80\ntargetPort: 3000\ntype: LoadBalancer",
      "content": "Explain Kubernetes deployment strategies and configurations."
    },
    {
      "id": "imported-deployment-devops-1759191594554-0",
      "isActive": true,
      "createdAt": "2025-09-30T00:19:54.627Z",
      "options": [],
      "title": "Containerization with Docker",
      "importedAt": "2025-09-30T00:19:54.554Z",
      "codeBlock": "# Multi-stage build for Node.js application\nFROM node:18-alpine AS builder\n\n# Set working directory\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json ./\n\n# Install dependencies\nRUN npm ci --only=production && npm cache clean --force\n\n# Copy source code\nCOPY . .\n\n# Build application\nRUN npm run build\n\n# Production stage\nFROM node:18-alpine AS production\n\n# Create non-root user\nRUN addgroup -g 1001 -S nodejs\nRUN adduser -S nextjs -u 1001\n\n# Set working directory\nWORKDIR /app\n\n# Copy built application\nCOPY --from=builder --chown=nextjs:nodejs /app/dist ./dist\nCOPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules\nCOPY --from=builder --chown=nextjs:nodejs /app/package*.json ./\n\n# Switch to non-root user\nUSER nextjs\n\n# Expose port\nEXPOSE 3000\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD curl -f http://localhost:3000/health || exit 1\n\n# Start application\nCMD [\"npm\", \"start\"]",
      "content": "Explain Docker containerization and best practices.",
      "correctAnswer": null,
      "topics": [
        "Docker",
        "CI/CD",
        "AWS",
        "Build Tools"
      ],
      "learningPaths": [
        "deployment-devops"
      ],
      "difficulty": "intermediate",
      "source": "QuestionsBank",
      "explanation": "**1. Dockerfile Best Practices:**\n\n# Multi-stage build for Node.js application\nFROM node:18-alpine AS builder\n\n# Set working directory\nWORKDIR /app\n\n# Copy package files\nCOPY package*.json ./\n\n# Install dependencies\nRUN npm ci --only=production && npm cache clean --force\n\n# Copy source code\nCOPY . .\n\n# Build application\nRUN npm run build\n\n# Production stage\nFROM node:18-alpine AS production\n\n# Create non-root user\nRUN addgroup -g 1001 -S nodejs\nRUN adduser -S nextjs -u 1001\n\n# Set working directory\nWORKDIR /app\n\n# Copy built application\nCOPY --from=builder --chown=nextjs:nodejs /app/dist ./dist\nCOPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules\nCOPY --from=builder --chown=nextjs:nodejs /app/package*.json ./\n\n# Switch to non-root user\nUSER nextjs\n\n# Expose port\nEXPOSE 3000\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\nCMD curl -f http://localhost:3000/health || exit 1\n\n# Start application\nCMD [\"npm\", \"start\"]\n\n**2. Docker Compose:**\n\n# docker-compose.yml\nversion: '3.8'\n\nservices:\napp:\nbuild: .\nports:\n- '3000:3000'\nenvironment:\n- NODE_ENV=production\n- DATABASE_URL=postgresql://user:password@db:5432/mydb\ndepends_on:\n- db\n- redis\nvolumes:\n- ./logs:/app/logs\nrestart: unless-stopped\nnetworks:\n- app-network\n\ndb:\nimage: postgres:15-alpine\nenvironment:\n- POSTGRES_DB=mydb\n- POSTGRES_USER=user\n- POSTGRES_PASSWORD=password\nvolumes:\n- postgres_data:/var/lib/postgresql/data\n- ./init.sql:/docker-entrypoint-initdb.d/init.sql\nports:\n- '5432:5432'\nrestart: unless-stopped\nnetworks:\n- app-network\n\nredis:\nimage: redis:7-alpine\nports:\n- '6379:6379'\nvolumes:\n- redis_data:/data\nrestart: unless-stopped\nnetworks:\n- app-network\n\nnginx:\nimage: nginx:alpine\nports:\n- '80:80'\n- '443:443'\nvolumes:\n- ./nginx.conf:/etc/nginx/nginx.conf\n- ./ssl:/etc/nginx/ssl\ndepends_on:\n- app\nrestart: unless-stopped\nnetworks:\n- app-network\n\nvolumes:\npostgres_data:\nredis_data:\n\nnetworks:\napp-network:\ndriver: bridge\n\n**3. Docker Optimization:**\n\n# Optimized Dockerfile with caching\nFROM node:18-alpine AS base\n\n# Install dependencies only when needed\nFROM base AS deps\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci --only=production && npm cache clean --force\n\n# Rebuild the source code only when needed\nFROM base AS builder\nWORKDIR /app\nCOPY package*.json ./\nRUN npm ci\nCOPY . .\nRUN npm run build\n\n# Production image, copy all the files and run next\nFROM base AS runner\nWORKDIR /app\n\nENV NODE_ENV production\n\nRUN addgroup --system --gid 1001 nodejs\nRUN adduser --system --uid 1001 nextjs\n\nCOPY --from=builder /app/public ./public\nCOPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./\nCOPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static\n\nUSER nextjs\n\nEXPOSE 3000\n\nENV PORT 3000\nENV HOSTNAME \"0.0.0.0\"\n\nCMD [\"node\", \"server.js\"]",
      "isComplete": false,
      "updatedAt": "2025-09-30T00:19:54.627Z",
      "category": "Deployment & DevOps",
      "type": "code"
    }
  ]
}